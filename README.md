# Proyectos para la materia Procesamiento de Lenguaje Natural I (NLP) - Curso de Especializaci√≥n en Inteligencia Artificial - FIUBA

![Banner del Curso NLP](https://github.com/ezecaa/nlp1/blob/main/portrait.png)

Este repositorio es un portfolio que recopila los proyectos y desaf√≠os que desarroll√© como parte de mi curso de **Procesamiento de Lenguaje Natural I**. Aqu√≠ se reflejan las habilidades y conocimientos adquiridos en el dise√±o, implementaci√≥n y evaluaci√≥n de modelos de lenguaje, sistemas de traducci√≥n autom√°tica, bots conversacionales y otras aplicaciones de NLP utilizando diversas t√©cnicas.

Cada proyecto aborda un problema espec√≠fico de NLP, desde la preparaci√≥n de datos hasta la implementaci√≥n y evaluaci√≥n de modelos.

---

## Trabajos Pr√°cticos del Curso

A continuaci√≥n, se presenta una breve descripci√≥n de cada uno de los desaf√≠os o trabajos pr√°cticos realizados, con enlaces directos a los notebooks correspondientes para su exploraci√≥n detallada.

---

### **Trabajo Pr√°ctico 1: Clasificaci√≥n de Texto y Similitud (TP1.ipynb)**

**Descripci√≥n:**
En este trabajo pr√°ctico inicial, se exploraron los fundamentos del preprocesamiento de texto y la aplicaci√≥n de modelos cl√°sicos de Machine Learning para tareas de NLP. Se trabaj√≥ con algoritmos de clasificaci√≥n como **Naive Bayes Multinomial y ComplementNB** para clasificar documentos. Adem√°s, se investig√≥ la **similitud de documentos y palabras**, sentando las bases para la representaci√≥n vectorial del texto.

**Tecnolog√≠as Clave:**
* Python
* Scikit-learn (para clasificaci√≥n y herramientas de ML)
* Numpy (para manipulaci√≥n de datos)
* Conceptos de preprocesamiento de texto y vectorizaci√≥n

**Notebook:** [TrabajoPractico1/TP1.ipynb](TrabajoPractico1/TP1.ipynb)
* Abrir en Google Colab: [TP1.ipynb](https://colab.research.google.com/github/ezecaa/nlp1/blob/main/TrabajoPractico1/TP1.ipynb)

---

### **Trabajo Pr√°ctico 2: Custom Embeddings con Gensim (TP2.ipynb)**

**Descripci√≥n:**
Este trabajo pr√°ctico se centr√≥ en la creaci√≥n y an√°lisis de **embeddings de palabras personalizados** utilizando la librer√≠a **Gensim**. Se entrenaron vectores de palabras sobre un dataset espec√≠fico (la obra "Hamlet" de William Shakespeare), y se explor√≥ el espacio de embeddings para identificar y explicar **similitudes y diferencias entre palabras**. Se realizaron visualizaciones para comprender mejor las relaciones sem√°nticas capturadas por los vectores.

**Tecnolog√≠as Clave:**
* Python
* Gensim (para Word2Vec u otros embeddings)
* An√°lisis de similitud de vectores
* Visualizaci√≥n de embeddings

**Notebook:** [TrabajoPractico2/TP2.ipynb](TrabajoPractico2/TP2.ipynb)
* Abrir en Google Colab: [TP2.ipynb](https://colab.research.google.com/github/ezecaa/nlp1/blob/main/TrabajoPractico2/TP2.ipynb)

---

### **Trabajo Pr√°ctico 3: Modelo de Lenguaje con Tokenizaci√≥n por Caracteres (TP3.ipynb)**

**Descripci√≥n:**
En este desaf√≠o, se implement√≥ un modelo de lenguaje a nivel de caracteres utilizando Redes Neuronales Recurrentes (RNNs), espec√≠ficamente unidades LSTM. El objetivo principal fue aprender la distribuci√≥n de probabilidad de secuencias de caracteres para poder generar texto coherente. Se exploraron conceptos fundamentales como la tokenizaci√≥n a nivel de car√°cter, la estructuraci√≥n de datasets para modelos de lenguaje, y la importancia de m√©tricas como la perplejidad. Se trabaj√≥ en la optimizaci√≥n del entrenamiento y se experiment√≥ con estrategias de generaci√≥n de texto como *greedy search* y *beam search*, analizando el impacto de la temperatura en la diversidad de las salidas generadas.

**Tecnolog√≠as Clave:**
* TensorFlow / Keras
* LSTMs (Long Short-Term Memory) - GRU
* Tokenizaci√≥n por caracteres
* Perplejidad (Perplexity)
* Greedy Search, Beam Search, Sampling con Temperatura

**Notebook:** [TrabajoPractico3/TP3.ipynb](TrabajoPractico3/TP3.ipynb)
* Abrir en Google Colab: [TP3.ipynb](https://colab.research.google.com/github/ezecaa/nlp1/blob/main/TrabajoPractico3/TP3.ipynb)

---

### **Trabajo Pr√°ctico 4a: Traductor Autom√°tico Seq2Seq con LSTM (TP4a.ipynb)**

**Descripci√≥n:**
Este proyecto se centr√≥ en la creaci√≥n de un sistema de **traducci√≥n autom√°tica neuronal (NMT)** utilizando la arquitectura **Encoder-Decoder con LSTMs**. El modelo fue entrenado para traducir frases entre diferentes idiomas (basado en datos de Anki). Se implement√≥ un Encoder para codificar la frase de entrada en un vector de contexto y un Decoder para generar la frase traducida, abordando el preprocesamiento de datos espec√≠fico para NMT y la inferencia paso a paso.

**Tecnolog√≠as Clave:**
* TensorFlow / Keras
* Arquitectura Encoder-Decoder
* LSTMs (Long Short-Term Memory)
* Preprocesamiento de datos para NMT
* Inferencia de modelos Seq2Seq

**Notebook:** [TrabajoPractico4/TP4a.ipynb](TrabajoPractico4/TP4a.ipynb)
* Abrir en Google Colab: [TP4a.ipynb](https://colab.research.google.com/github/ezecaa/nlp1/blob/main/TrabajoPractico4/TP4a.ipynb)

---

### **Trabajo Pr√°ctico 4b: Bot Conversacional (Question-Answering) con LSTM y FastText (TP4b.ipynb)**

**Descripci√≥n:**
El objetivo de este desaf√≠o fue desarrollar un **bot conversacional de Preguntas y Respuestas (QA)** utilizando el dataset ConvAI2. Se aplicaron t√©cnicas de procesamiento de lenguaje natural y se construy√≥ un modelo basado en redes recurrentes, integrando **embeddings FastText** para la representaci√≥n de palabras. Se exploraron los resultados del modelo en la generaci√≥n de respuestas y se discutieron observaciones importantes como el **overfitting** y la necesidad de optimizaci√≥n de par√°metros y recursos.

**Tecnolog√≠as Clave:**
* TensorFlow / Keras
* Modelos de Seq2Seq (aplicado a QA)
* Embeddings FastText
* Preprocesamiento de datos para QA
* Manejo de di√°logos y generaci√≥n de respuestas

**Notebook:** [TrabajoPractico4/TP4b.ipynb](TrabajoPractico4/TP4b.ipynb)
* Abrir en Google Colab: [TP4b.ipynb](https://colab.research.google.com/github/ezecaa/nlp1/blob/main/TrabajoPractico4/TP4b.ipynb)

---

## üîë C√≥mo Ver los Notebooks en Colab

Si deseas ejecutar o interactuar con los notebooks directamente en Google Colab, puedes hacer clic en los enlaces "Abrir en Google Colab" proporcionados para cada trabajo pr√°ctico. Aseg√∫rate de tener una cuenta de Google activa para acceder.

---

## üõ†Ô∏è Configuraci√≥n del Entorno

Los proyectos fueron desarrollados en un entorno de Google Colab, utilizando librer√≠as populares de Python para Machine Learning y Procesamiento de Lenguaje Natural.

**Requisitos Generales:**
* Python 3.x
* TensorFlow / Keras
* Numpy
* Pandas
* Gensim (para embeddings)
* Otras librer√≠as espec√≠ficas seg√∫n el TP (ej. NLTK, spaCy, Tqdm, Matplotlib, Seaborn)

Las dependencias exactas se listan en las primeras celdas de cada notebook.

---

## ü§ù Contribuciones y Contacto

Este repositorio es una muestra de mi aprendizaje y desarrollo en el campo del NLP. Estoy abierto a nuevas ideas y colaboraciones.

**Contacto:**
* GitHub: [ezecaa](https://github.com/ezecaa)

---

**¬°Gracias por visitar mi portfolio!**
